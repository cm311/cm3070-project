{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66274594-9fb4-4030-b7b4-29ab983c5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.nlp_analysis as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2829e08f-c0e0-41b2-a6e3-342332aaa24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying en articles...\n",
      "Number of articles retrieved: 3181\n",
      "Building corpus from 3181 articles...\n",
      "Progress: 48.07 %    Fail Rate: 7.91 %  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python39\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete              Fail Rate: 7.83 %  \n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030113697052001953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json",
       "rate": null,
       "total": 25998,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973b3bb1de48425ca54995b0649516c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 15:19:40 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2022-08-28 15:19:40 INFO: Use device: cpu\n",
      "2022-08-28 15:19:40 INFO: Loading: tokenize\n",
      "2022-08-28 15:19:40 INFO: Loading: pos\n",
      "2022-08-28 15:19:41 INFO: Loading: lemma\n",
      "2022-08-28 15:19:41 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "articles = nlp.create_articles_from_keyphrase('american', '2022-07-01', '2022-08-15')\n",
    "nlp.remove_short(articles)\n",
    "corpus = nlp.run_stanza_pipeline(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae66e095-1ff9-4759-9d35-8cf59dcf6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for sentence in corpus.sentences:\n",
    "    new_sentence = []\n",
    "    for word in sentence.words:\n",
    "        if word.lemma != None:\n",
    "            new_sentence.append(word.lemma.lower())\n",
    "    new_sentence = nlp.stopword_removal(new_sentence)\n",
    "    all_sentences.append(new_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd4472ba-a879-4e11-a95c-50992b74f887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('america', 0.6519256830215454),\n",
       " ('carp', 0.5704261660575867),\n",
       " ('hawaiian', 0.548775851726532),\n",
       " ('hawaiians', 0.5237983465194702),\n",
       " ('descent', 0.5214378237724304),\n",
       " ('pacific', 0.5198360681533813),\n",
       " ('19th', 0.5195847749710083),\n",
       " ('islander', 0.4967053532600403),\n",
       " ('spirit', 0.4668402671813965),\n",
       " ('21st', 0.4559464752674103)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nlp.Word2Vec(sentences=all_sentences, window=4, min_count=10, workers=4)\n",
    "similar = model.wv.most_similar('american')\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0fa28329-1a22-4cd9-a640-77d4b61f4a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('americana', 0.9787948131561279),\n",
       " ('anti-american', 0.9697635769844055),\n",
       " ('@americanair', 0.956495463848114),\n",
       " ('americorps', 0.9354724884033203),\n",
       " ('america', 0.9300878643989563),\n",
       " ('erica', 0.8559512495994568),\n",
       " ('amex', 0.8433609008789062),\n",
       " ('amc', 0.7826496362686157),\n",
       " ('amg', 0.7573833465576172),\n",
       " ('hurricane', 0.7524666786193848)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model2 = FastText(window=4, min_count=10, sentences=all_sentences, workers=4)\n",
    "similar = model2.wv.most_similar('american')\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefed3d-5529-4006-ad05-eb3938691130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "682304ca-c9b2-499e-8235-a6b6ca4d6175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American', 'past', 'third', 'free', 'local']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "lemmas = nlp.stopword_removal(lemmas)\n",
    "freq = nltk.FreqDist(lemmas)\n",
    "\n",
    "words = []\n",
    "for i in freq.most_common()[200:]:\n",
    "    if i[0] in adjectives:\n",
    "        words.append(i[0])\n",
    "    if len(words) == 5:\n",
    "        break\n",
    "\n",
    "words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b0ffa6-c31c-4044-9c68-253c2bbeea33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 641),\n",
       " ('say', 413),\n",
       " ('I', 374),\n",
       " ('year', 184),\n",
       " ('go', 144),\n",
       " ('get', 131),\n",
       " ('make', 126),\n",
       " ('one', 123),\n",
       " ('time', 120),\n",
       " ('also', 112)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b3a25-c23f-4166-ad11-0d6f0f3ad542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
